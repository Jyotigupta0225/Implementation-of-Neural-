{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Neural Network (Logistic Regression as a NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data (cat/non-cat)\n",
    "def load_dataset():\n",
    "    \"\"\"Loads the Cat vs Non-Cat dataset\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train, y_train, X_test, y_test, classes: Arrays\n",
    "    Dataset splitted into train and test with classes\n",
    "    \"\"\"\n",
    "    train_dataset = h5py.File('C:\\Users\\user\\Documents\\GitHub\\Implementation-of-Neural-Network\\Neural Network (Scratch)\\datasets/train_catvnocat.h5' , 'r'\n",
    "    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:])\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating sigmoid\n",
    "def sigmoid(z):\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'datasets/train_catvnoncat.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8eee2d4601d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Printing the shape of the training and testing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_set_x_orig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set_y_orig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set_x_orig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set_y_orig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_set_x_orig shape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set_x_orig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_set_y_orig'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_set_y_orig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_set_x_orig\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_set_x_orig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-7ab97b40aa10>\u001b[0m in \u001b[0;36mload_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mDataset\u001b[0m \u001b[0msplitted\u001b[0m \u001b[0minto\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \"\"\"\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datasets/train_catvnoncat.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtrain_set_x_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train_set_x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtrain_set_y_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train_set_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\computervisionenv\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\computervisionenv\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'datasets/train_catvnoncat.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# Printing the shape of the training and testing data\n",
    "train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes = load_dataset()\n",
    "print('train_set_x_orig shape', train_set_x_orig.shape)\n",
    "print('train_set_y_orig',train_set_y_orig.shape)\n",
    "print(\"test_set_x_orig\",test_set_x_orig.shape)\n",
    "print(\"test_set_y_orig\",test_set_y_orig.shape)\n",
    "print('classes',classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the training and test examples\n",
    "def preprocess(train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig):\n",
    "    train_x = train_set_x_orig.reshape(train_set_x_orig.shape[0], train_set_x_orig.shape[1]*train_set_x_orig.shape[2]*train_set_x_orig.shape[3])/255.\n",
    "    test_x = test_set_x_orig.reshape(test_set_x_orig.shape[0],test_set_x_orig.shape[1]*test_set_x_orig.shape[2]*test_set_x_orig.shape[3])/255.\n",
    "    train_y = train_set_y_orig.reshape(-1,1)\n",
    "    test_y = test_set_y_orig.reshape(-1,1)\n",
    "    return train_x,test_x,train_y,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining initail weights to w and b\n",
    "def initial_weights(X):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (X.shape[1], 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    X -- training dataset\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (X.shape[1], 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "    w = np.zeros([X.shape[1] ,1])\n",
    "    b =0\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORWARD PROPAGATION\n",
    "def forward_propagate(X,w,b):\n",
    "    \"\"\"\n",
    "    This functions performs forward propagation and calculates output value\n",
    "    \n",
    "    Argument:\n",
    "    X -- training dataset\n",
    "    w -- weight\n",
    "    b -- bias\n",
    "    \n",
    "    Returns:\n",
    "    A -- yhat(predicted output) for the training data\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    z = (np.dot(X,w)+b)\n",
    "    A = sigmoid(z)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating loss using the cost function\n",
    "def costfunction(Y,A):\n",
    "    \"\"\"\n",
    "    This function calculates the loss between the predicted and actual output\n",
    "    \n",
    "    Argument:\n",
    "    Y -- actual output\n",
    "    A -- predicted output\n",
    "    \n",
    "    Returns:\n",
    "    cost -- loss between the predicted and actual output\n",
    "    \"\"\"\n",
    "    m = Y.shape[0]\n",
    "    cost = -1/m*np.sum(Y*np.log(A) + (1-Y)*np.log(1-A))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BACKWARD PROPAGATION (TO FIND GRADIENT)\n",
    "def back_prpagate(X,Y,A):\n",
    "    \"\"\"Performs backward propagation and calculates derivative value for a layer\n",
    "\n",
    "    Arguments:\n",
    "    X -- array_like Data\n",
    "    Y -- array_like True labels\n",
    "    A -- predicted output\n",
    "\n",
    "    Returns:\n",
    "    dw -- derivative of weight\n",
    "    db -- derivative of bias\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    dz = (A-Y)\n",
    "    dw = 1/m*(np.dot(X.T,dz))\n",
    "    db = 1/m*(np.sum(dz))\n",
    "    return dw,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the weight and bias\n",
    "def update_weights(w, b, dw,db, learning_rate):\n",
    "    \"\"\"\n",
    "    This function updates the weight and bias\n",
    "    \n",
    "    Argument:\n",
    "    w -- weight\n",
    "    b -- bias\n",
    "    dw -- derivative of weight\n",
    "    db -- derivative of bias\n",
    "    \n",
    "    Returns:\n",
    "    w -- weight\n",
    "    b -- bias\n",
    "    \"\"\"\n",
    "    \n",
    "    w = w-learning_rate*dw\n",
    "    b = b-learning_rate*db\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model with the number of iterations\n",
    "def train_model(X,Y,test_x,test_y,w,b, learning_rate = 0.01, num_iterations = 100):\n",
    "    \"\"\"\n",
    "    This function  trains the model with the number of iterations\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weight\n",
    "    b -- bias, a scalar\n",
    "    X -- training data \n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    \n",
    "    Returns:\n",
    "    w -- weight\n",
    "    b -- bias\n",
    "    dw -- derivative of weight\n",
    "    db -- derivative of bias\n",
    "    cost -- loss     \n",
    "    \"\"\"\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        A = forward_propagate(X,w,b)\n",
    "        cost = costfunction(Y,A)\n",
    "        dw,db = back_prpagate(X,Y,A)\n",
    "        w,b = update_weights(w,b,dw,db,learning_rate)\n",
    "\n",
    "        if i%(num_iterations/10) == 0:\n",
    "            \n",
    "            A_train = np.where(forward_propagate(X,w,b)>0.5 , 1, 0)\n",
    "            A_test = np.where(forward_propagate(test_x,w,b)>0.5 , 1, 0)\n",
    "\n",
    "            acc_train = accuracy_score(Y, A_train)\n",
    "            acc_test = accuracy_score(test_y , A_test)\n",
    "            print('Iteration: ', i, end = '')\n",
    "            print('\\t\\tTraining Accuracy: {:.4f}\\t'.format(acc_train),end = '')\n",
    "            print('Testing Accuracy: {:.4f}'.format(acc_test))\n",
    "    return w,b,dw,db, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes, num_iterations, learning_rate):\n",
    "    train_x,test_x,train_y,test_y = preprocess(train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig)\n",
    "    w,b = initial_weights(train_x)\n",
    "    w,b,dw,db, cost = train_model(train_x,train_y,test_x,test_y,w,b, learning_rate = learning_rate, num_iterations = num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter iterations : 1000\n",
      "Enter learning rate : 0.01\n",
      "Iteration:  0\t\tTraining Accuracy: 0.6555\tTesting Accuracy: 0.3400\n",
      "Iteration:  100\t\tTraining Accuracy: 0.6555\tTesting Accuracy: 0.3400\n",
      "Iteration:  200\t\tTraining Accuracy: 0.7225\tTesting Accuracy: 0.3600\n",
      "Iteration:  300\t\tTraining Accuracy: 0.6938\tTesting Accuracy: 0.3200\n",
      "Iteration:  400\t\tTraining Accuracy: 0.7321\tTesting Accuracy: 0.3600\n",
      "Iteration:  500\t\tTraining Accuracy: 0.7895\tTesting Accuracy: 0.4400\n",
      "Iteration:  600\t\tTraining Accuracy: 0.9091\tTesting Accuracy: 0.6200\n",
      "Iteration:  700\t\tTraining Accuracy: 0.9665\tTesting Accuracy: 0.7000\n",
      "Iteration:  800\t\tTraining Accuracy: 0.9713\tTesting Accuracy: 0.7000\n",
      "Iteration:  900\t\tTraining Accuracy: 0.9809\tTesting Accuracy: 0.7200\n"
     ]
    }
   ],
   "source": [
    "train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes = load_dataset()\n",
    "num_iterations = int(input(\"Enter iterations : \"))\n",
    "learning_rate = float(input(\"Enter learning rate : \"))\n",
    "\n",
    "model(train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes, num_iterations, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
